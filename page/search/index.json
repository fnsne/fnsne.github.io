[{"content":" 安裝certbot\nsudo apt install certbot 使用certbot申請SSL憑證\nsudo certbot certonly -d \u0026lt;DOMAINNAME\u0026gt; --manual certonly：表示只需要申請憑證即可。certbot還有支援一些常見的server替換SSL的功能，如apache、nginx等 --manual：表示要使用互動界面來申請憑證。 注意：使用\u0026ndash;manual的方式申請的憑證，除非有配合使用其它驗證插件，否則無法自動renew。\n這個方式申請的憑證有提供兩種預設方式驗證\n會產生一個challenge檔案，然後讓我們放到要使用這個憑證的機器（至少是這個domain name會連到的機器）的根目錄下指定的資料夾，讓ACME驗證可以使用申請的domain name加上給定的ACME資料夾，拿到申請的檔案。 直接會在目標機器上加上一個短暫的server，做到在指定的網址回傳上述的challenge檔案。 另外certbot其實還提供了其它的驗證方式，例如DNS\nsudo certbot certonly -d \u0026lt;DOMAINNAME\u0026gt; --preferred-challenges dns --manual certbot會在申請的互動界面，產生一個申請憑證網域的challenge key和value，申請人要到DNS託管服務，例如GoDaddy、AWS Route53等服務上，對要申請憑證的網域使用certbot產出的key value來建立一筆TXT設定，讓Let’s Encrypt確定要申請的網域是屬於你的。 使用Route53插件驗證 其實就是藉由Route53的API，讓插件替我們做完把ACME Chellenge TXT設定到DNS Server上的這段流程。所以需要設定AWS的access client到申請憑證的機器上。\n安裝certbot-dns-route53\nsudo apt install python3-certbot-dns-route53 其它plugin的名稱也是使用相同的pattern: python3-certbot-dns-\u0026lt;PLUGIN\u0026gt; 設定AWS的access client\n到AWS設定一個Policy\n{ \u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;certbot-dns-route53 sample policy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53:GetChange\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] }, { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;route53:ChangeResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34; : [ \u0026#34;arn:aws:route53:::hostedzone/YOURHOSTEDZONEID\u0026#34; ] } ] } Version的值不能改，這是告訴AWS要用這版的規則來看這個Policy\nYOURHOSTEDZONEID：去Route53點選要設定的domain name，就會寫出它的host zone ID（託管區域ID）了。\n建立一個IAM account，並且授予它上面的policy權限\n在要執行certbot的機器上建立一個config檔，叫~/.aws/config內容如下\n[default] aws_access_key_id=\u0026lt;IAM的ID\u0026gt; aws_secret_access_key=\u0026lt;IAM的secret key\u0026gt; 注意，如果執行certbot需要使用sudo來執行，這個config必須改放到/root/.aws/config。\n執行certbot\nsudo certbot certonly --dns-route53 -d rd2.team.araliadata.io 如果有要申請wildcard網域，需要多加上*.rd2.team.araliadata.io才需要有這段\n—-post-hook：當certbot完成執行後，會在本地執行的動作。\n設定排程執行sudo certbot renew，它會自行檢查是否有憑證快要到期了，如果快要到期才會真的再次申請新的憑證下來。\nsudo certbot renew --cert-name \u0026lt;憑證名稱\u0026gt; --post-hook \u0026#34;docker compose -f /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml down \u0026amp; /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml up -d\u0026#34; 憑證名稱：可以使用certbot certificates來查看\ncertbot renew：當憑證會在30天內到期時，真的去申請新的憑證，還未到期不會真的去申請新的憑證。\nex: 每週一檢查一次\n#sudo crontab -e 0 0 * * 1 sudo certbot renew --cert-name rd2.team.araliadata.io --post-hook \u0026#34;docker compose -f /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml down \u0026amp; /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml up -d\u0026#34; 提醒 可以先加上 --dry-run ，用來測試server申請憑證是否能成功，以防操作太多次，超過額度，不給申請。\n使用--manual的憑證申請，不能使用renew功能，除非有加上authentication hook，例如上面提到的route-53 plugin。\nroute-53 plugin其實就是用script連到route-53服務，新增對應的ACME challenge TXT。\nACME的驗證（--preferred-challenges），如果選擇使用DNS的方式驗證，需要使用--manual才能做。除非加上DNS插件驗證（如route53）。\n","date":"2024-07-04T21:09:08+08:00","permalink":"http://coding.fnsne.com/posts/%E5%A6%82%E4%BD%95%E7%94%A8certbot%E7%94%B3%E8%AB%8B-lets-encrypt-%E7%9A%84%E6%86%91%E8%AD%89/","title":"如何用certbot申請 Let’s Encrypt 的憑證"},{"content":"在乾淨環境建立k8s環境 使用k8sadmin架設k8s環境\nlinux環境設定 在開始安裝之前，需要先把host給設定好，所以會先說明要做哪些動作。\n關閉swap功能 關閉swap\nswapoff -a 編輯 /etc/fstab\nvim /etc/fstab 把檔案裡面 /swapfile 開頭的這行註解掉\n安裝docker 安裝所需的工具\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install ca-certificates curl gnupg lsb-release 下載docker並新增官方的GPG key\nsudo mkdir -m 0755 -p /etc/apt/keyrings \u0026amp;\u0026amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 設定放docker的repository\necho \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 安裝docker engine\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 測試有沒有成功安裝docker engine\nsudo docker run hello-world 調整權限，這樣以後就不需要每個docker command前面還要加sudo了。\nsudo usermod -aG docker $USER 安裝apt-transport-https、ca-certificates、curl sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl 加上 Kubernetes apt 的repo 下載google cloud public signing key\nsudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg 加上 apt 的repo\necho \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list 安裝k8s環境執行用的工具 更新apt並安裝kubeadm, kubectl, kubelet，並鎖定版本 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y kubelet kubeadm kubectl \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubeadm kubectl 安裝cri-dockerd Container Runtime Interface (CRI)：Kubelet會使用CRI 界面來建立container。\n到cri-dockerd的repo上面，release找到對應的版本。複製下載鏈接，使用wget在機器上面下載下來\n例如ubuntu的\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.1/cri-dockerd_0.3.1.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.1.3-0.ubuntu-jammy_amd64.deb 檢查有沒有安裝成功並跑起來\nsudo systemctl status cri-docker.socket 啟動k8s cluster 如果有需要的話，可以使用kubeadm init -h看看，上面有更多資訊可以看\n使用kubeadm建立cluster\nsudo kubeadm init {options} options常用的有\n--pod-network-cidr\n希望給pod的網段例如：10.244.0.0/16\n要注意，如果和要使用的CNI的預設不一樣，到時候得要在CNI上面設定一下。\n--apiserver-advertise-address\n來指定api server的網址，如果沒有設定，會使用預設的$網路$ 界面。 --apiserver-bind-port\napiserver的port，預設是6443\n-apiserver-bind-port int32 Default: 6443Port for the API Server to bind to. (View Source)\n--service-cidr\n來指定service到時候被產生出來的virtual ip的range 可以使用--cri-socket={CRI的socket}指定特定的cri\n例子\nsudo kubeadm init --pod-network-cidr 192.167.0.0/16 --cri-socket unix:/var/run/cri-dockerd.sock --service-cidr 192.168.192.0/18 做錯了可以使用kubeadm reset來關閉剛剛啟動（或者失敗）的k8s cluster。\n最後為了讓現在的帳號可以使用kubectl，而不是使用root帳號，需要做以下的操作\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 安裝CNI Container Network Interface(CNI)\n負責container之間、還有對外的各種溝通\n負責創建、回收container時，用到的Network的功能。\n常見的CNI有Flannel(已停止維護)、Calico。\n安裝Flannel的方法：\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 安裝Calico的方法：\n下載yaml檔\nwget https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml 安裝並啟動\nkubectl apply -f calico.yaml 以上就完成了在Linux上架好一個k8s環境的controller plane (k8s叢集的master)了。但是這個時候還沒辦法在k8s環境裡面，在預設的情況下，controller plane所在的host會有設定一個汙點（類似tag的東西），不讓任何非系統運行是所需的Pod（k8s運行的基本單位）被啟動起來。所以還需要再把其它機器加進來k8s cluster中，才能正常運作。\n把其它臺機器加入這個k8s cluster 和controller prlane一樣，也要先設定好環境：linux環境設定和安裝k8s環境執行用的工具\n使用上面在建立cluster時，最後在畫面上顯示的join命令。\nkubeadm koin --token {cluster產生的token} 要注意的是，token只有24小時的有效期限。過期了需要回到controller plane產生新的token\nkubeadm token create --print-join-command ","date":"2023-06-29T09:34:49+08:00","permalink":"http://coding.fnsne.com/posts/%E5%9C%A8%E4%B9%BE%E6%B7%A8%E7%92%B0%E5%A2%83%E5%BB%BA%E7%AB%8Bk8s%E7%92%B0%E5%A2%83/","title":"在乾淨環境建立k8s環境"},{"content":"Local Path Provisioner 是一個 Container Storage Interface (CSI)，也就是用來提供k8s環境下建立Persistent Volume (PV)的插件\n安裝 command\nkubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml 會建立local-path-storage這個namespace，要查看運行狀態，可以到裡面看log\nkubectl -n local-path-storage logs pods/local-path-provisioner-7f8667b75c-hjrrb 使用configmap來給予設定\nkind: ConfigMap apiVersion: v1 metadata: name: local-path-config namespace: local-path-storage data: config.json: |- { \u0026#34;nodePathMap\u0026#34;:[ { \u0026#34;node\u0026#34;:\u0026#34;DEFAULT_PATH_FOR_NON_LISTED_NODES\u0026#34;, \u0026#34;paths\u0026#34;:[\u0026#34;/opt/local-path-provisioner\u0026#34;] }, { \u0026#34;node\u0026#34;:\u0026#34;yasker-lp-dev1\u0026#34;, \u0026#34;paths\u0026#34;:[\u0026#34;/opt/local-path-provisioner\u0026#34;, \u0026#34;/data1\u0026#34;] }, { \u0026#34;node\u0026#34;:\u0026#34;yasker-lp-dev3\u0026#34;, \u0026#34;paths\u0026#34;:[] } ] } setup: |- #!/bin/sh set -eu mkdir -m 0777 -p \u0026#34;$VOL_DIR\u0026#34; teardown: |- #!/bin/sh set -eu rm -rf \u0026#34;$VOL_DIR\u0026#34; helperPod.yaml: |- apiVersion: v1 kind: Pod metadata: name: helper-pod spec: containers: - name: helper-pod image: busybox config.json說明 nodePathMap：用來表示在各自的Node上，存資料的位置，規則如下 沒有設定path的node會套用DEFAULT_PATH_FOR_NON_LISTED_NODES的設定 如果有列出來，但path是空的，代表這個Node不會允許用local-path-provisioner來建pv 每個node的path可以給好幾個位置，當裡面超過一個位置，每次建的時候會隨機選一個來用。 path一定要是絕對路徑 在同個node裡面，同一個path不能重複列。 同一個node不能重複列出來。 不允許使用/ 根目錄 sharedFileSystemPath: 假如有一個file system有被mount在所有的Node上時，可以使用這個設定來指定，指定都用同一個位置。 和nodePathMap互斥，所以當有使用sharedFileSystemPath時，nodePathMap一定要是[] 只有使用了sharedFileSystemPath時，才會支援ReadOnlyMany、ReadWriteMany setup: 每個volume在建立之前會先做的script，用來準備node上volume資料夾用。 teardown：每個volume在被刪掉後會做的script，用來清掉node上volume資料夾用。 helperPod.yaml：用來執行setup和teardown的pod template setup和teardown上面可以使用的環境變數： 環境變數 說明 VOL_DIR 放置volume的路徑（nodePath寫的） VOL_MODE The PersistentVolume mode (Block or Filesystem). VOL_SIZE_BYTES Requested volume size in bytes. 設定storageClass來驅動local-path-provisioner provisioner欄位，官方Github寫的cluster.local/local-path-provisioner沒有用，反而要用rancher.io/local-path才有用。\napiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: incloud-lvm provisioner: rancher.io/local-path volumeBindingMode: WaitForFirstConsumer reclaimPolicy: Retain ","date":"2023-04-27T09:30:27+08:00","permalink":"http://coding.fnsne.com/posts/local-path-provisioner/","title":"Local Path Provisioner"},{"content":"關於鎖(lock) 畢業後，太久沒有用到相關的東西，概念開始有點混淆了，所以拿出恐龍本讀回來。順便做一篇筆記\n一些專有名詞 名稱 說明 cooperation process （協作行程） 會操作到共同資源的不同process critical section 在各種cooperation process 裡面會操作到共同資源的code區塊 鎖想解決的問題 在多核心多執行序問世之前的單核心的時代，是一個核心切換來切換去的做不同事，在時間區間上每個時間點都只有一個process正在被cpu執行，如下圖。\n而在多核心問世以後開始會出現一些問題，如下圖。\n開始會發生圖上，兩個核心會同時執行不同的process ，這個時候可能會發生互相改到資料的問題。例如process B和D是要在印表機上面印出現在電腦的時間，就有可能會發生一下的輸出：\n假設兩個核心在執行processB和D的時間點是15:38和15:40\n15:153:840 這是因為兩個核心互相搶著輸出到印表機，但是順序亂掉的緣故。為了解決這個問題，鎖的概念被提了出來。\n鎖的用途 用來保護注critical section（以上面的例子來看，是Process B和Process D裡面，執行輸出資料到印表機的code block）。強制這兩個critical section，在同一個時間裡面，頂多只能有一個執行，另一個想要執行，得要等到另一個結束後，才能開始動作。\n鎖的種類 mutex lock（互斥鎖） 又稱自旋鎖，會讓這個process一直卡在loop裡面，直到能夠存取資料後，才跳出迴圈，開始執行這個critical section。\n因為實際上是一直在執行loop的狀態下做等待資源釋放的，所以它不需要使用到context switch，在獲得資源後的切換速度很快。所以常常被使用在共用資源都只會被佔用短短時間的情境下使用。\nmutex lock的概念是一個被相同mutex lock保護起來的多個critical section，一個時間裡只能有一個被執行，其他都得要等待它mutex lock釋放後，才能繼續搶，搶到的才能執行。\nsemaphore lock（號誌鎖） 和mutex lock不同，可以設定資源同一時間下，最多可以有S個process同時執行，當同時執行的critical section數目大於S時，會被停下來，等待到同時執行的critical section小於S時，才能繼續搶進去執行。\n如果要用mutex lock的方式執行，會讓很多process一直在執行loop，對於資源的浪費太大了，所以在semaphore lock的時候，會採用將process 暫停，將address存到lock S 的list裡面。等到有process把S給釋放，此時CPU會將S裡面的list，取出一個process出來執行。\n我混淆的概念釐清 鎖不是鎖住cpu，而是鎖住其他一樣需要這個鎖的process，讓同一個鎖保護的同一個（或者不同個）critical section ，一次最多只能有1（或者semaphore lock設定的數字）個process存取。\n被鎖保護住的critical section，只要裡面有存取某個共用資源的code，就能讓這項資源被鎖給保護，不被濫用。\n結論 鎖的概念就是為了要保護有限的資源，不要被無限的取用。例如可以利用鎖來保護對同一個檔案的更改，讓這個檔案一次只能被一個process更新，防止檔案內資料變得亂七八糟的。\n","date":"2022-09-20T16:35:44+08:00","permalink":"http://coding.fnsne.com/posts/%E9%97%9C%E6%96%BC%E9%8E%96/","title":"關於鎖"},{"content":"網路上查到簡單說明transaction的例子，常常都是用轉賬來說明，但其實還有很多東西需要注意 帳戶轉賬，因為race condition的緣故，導致操作欄位的值被改錯。\nA有100，B有40。\nA轉100元給B，B轉20元給A，由兩個不同的client來處理操作。\n順序正確時：A會是減掉80\n但是當順序不正確，則數字會錯掉，例如A很早取得現在的餘額（100），但是更新數字0慢了，導致A最終變成0元，因為在B轉完帳後才更新值。\n以上的這個問題很明顯的是race condition。所謂的race condition是結果必須依賴與某種特定的順序，但是順序又並不是固定的，因此偶爾會出現錯誤。\n解決race condition的方法 為了要解決race condition，必須得要讓操作依照我們期望的順序才操作，才能預防不對的順序導致的錯誤。為了要達到這個目標，資料庫本身有提供兩種方法：\natomic update：資料庫提供的一個，對於單一欄位數值做相依於原本值的操作指令。這個操作過程會是atomic的，也就是不會操作到一半值被改掉而導致結果出錯。\nupdate products set quantity = quantity -1 where id = 1; 優點：因為只是對於欄位做簡單的數字運算並馬上更新上去，所以對於欄位的佔用時間相較下面的select for update較短，且資料庫會將這類atomic操作做優化，所以效能會比較好。\n缺點：只支援對於數值的簡單操作後更新，並不能做太複雜的運算。\nselect for update：這個操作被限制在transaction開起來的時候才能使用，使用時實際上就是將指定的欄位上一個更新的lock，此時直到commit之前，沒有其他client可以對這個欄位做任何更新。所以就能夠限制欄位更新的順序了。\nBegin; select quantity into $q from products where id = 1 for update; update products set quantity = $q-1; Commit; 優點：因為有上鎖了，所以幾乎可以用各種邏輯運算來更新欄位的值。\n缺點：因為會在欄位上面上鎖，並且持續到commit位置，所以對於效能會有很大的影響。\nversion scheme ：在table上面多新增一個欄位叫做version，來確定現在更新時的version，是否從拿值的時候到現在還沒有被更新過。程式可以藉由資料庫回傳的訊息，是否有更改到任何row來判斷是否更新成功。\nold_ver = `select money, version from bank where name = A` `update bank set money = 30, version = version + 1 where name = A and version = old_ver` 優點：能夠不使用任何鎖的時候實現。（或者還有其他我想不到的優點）\n缺點：可能會很浪費時間，尤其是當更新的頻率特別高的時候，可能很難可以得到把值更新下去的機會。並且失敗後得要重頭來過。可能會造成鎖的飢餓效應。\n一開始提到的例子裡面真正用到transaction功能的地方 利用transaction遇到錯誤時會rollback的特性，來在餘額小於0的時候，復原到還未轉賬之前的狀態。\n如何檢查餘額小於0，並在此時丟出錯誤呢？\n利用select for update鎖住欄位更新，在此時檢查，通過且做完操作後commit，釋放鎖。就可以避免此時有其他操作更動到這個帳戶的餘額。\n優點：可以實作各種複雜的檢查邏輯\n缺點：必須為這個帳戶的餘額上鎖，此時沒有其他人可以操作（也就是沒有其他人可以轉賬給他、領錢等操作），會導致效能低下。\n利用check constraint 來讓資料庫在欄位不符合規範的時候丟出錯誤。此時就可以配合transaction來rollback復原了。\n優點：因為check constraint是資料庫提供可以給欄位增加規範的設定，檢查會在更新的時候做，所以即使背後有使用鎖，所花費的時間會比用select for update還要少。\n缺點：只能依照資料庫提供的有限constraint來設定，並不一定能夠做到想要的規範。\n結論 遇到需要注意順序的操作，先試著能不能使用atomic update的方式來完成需求，沒有辦法的時候才會使用select for update的方式來限制進到這個transaction後，必須要操作完這邊的指令後，才能換別人改值。\n遇到需要檢查數值符不符合規範，先試著用check constraint來限制欄位，真的沒有辦法，才會採用select for update的方式來將欄位上鎖，來做檢查。\n參考資料 How to avoid the race condition and the negative value\ncheck constraint\nselect for update 詳解\ncheck constraint\n","date":"2022-09-14T16:22:17+08:00","permalink":"http://coding.fnsne.com/posts/%E8%B3%87%E6%96%99%E5%BA%AB%E7%9A%84%E5%90%8C%E6%AD%A5/","title":"資料庫的同步"},{"content":"卡片盒筆記寫作有兩種方式 卡片盒筆記的做法，現在網路上很多影片、文章都有教了，所以我就不贅述了，這篇文章主要是記錄我如何在heptabase上面實作卡片盒筆記的方式。目前理解到的用法大致上有兩種方式。\n闡述延伸自己論點的做法 google搜尋卡片盒筆記最容易找到的是閱讀前哨戰站長瓦基的文章，張永錫老師有一次有和瓦基、朱騏有直播 ，我在這邊大概知道了瓦基使用heptabase的方式 ，大致上就是持續將相同大分類（同board）的卡片做多張卡片凝聚出共通點、複雜卡片切割成多張不需要上下文即可理解的論述、依照因果關係或層級架構為卡片作出連結。最後依照這個的架構輸出成文章。瓦基卡片盒筆記的文章\n不同卡片蹦發出新的東西 在張永錫老師在hahow的卡片盒筆記術 中，教導的寫文章方式，則是直接將所有搜尋到有所關聯的卡片複製到whimsical上面，再來整理排序，變成一張完整的文章。\n對我來說 我使用卡片盒筆記的目的是學習知識、整理思路，對於卡片盒筆記術課程中教導的用whimsical 配合notion放卡片，對於長期的專案來說，持續分裂、內聚的卡片很難同步。我的結論是，這套流程只比較適合一次結束的專案。\n所以在理清我需要讓專案持續成長，又要能夠視覺化看到因果和層級架構 這件事後，我馬上就花錢訂閱了heptabase。\n我實際的做法 整理卡片（收集、整理材料） white board為一項大項知識的庫，在裡面可以持續新增卡片，並且整理出順序。 持續做以下的流程\n為簡單的卡片查詢資料\n將資料整理成多項能夠獨立闡述內容的卡片（永久卡片）\n看看多張卡片可不可以凝聚出共同性，將其抽出來寫成卡片\n看看有沒有卡片寫了太多項內容，將內容封裝成多張卡片\n如果卡片之間有因果關係、架構層級，為其加上connection。\n在這邊要注意一點是，link和connection感覺很相似，我剛開始很混亂，不知道要怎麼使用。因為同時想要能闡述延伸自己論點的做法 、不同卡片蹦發出新的東西 ，所以會想要讓所有卡片之間的關聯都是用connection來連結。但是這個做法會讓畫面變得很混亂，反而會阻礙思考。後來在釐清了我使用卡片筆記的主要用法是闡述延伸自己論點的做法 後，就決定只讓有因係、層級架構關聯的卡片，使用connection，而其他的關聯則是在卡片內文使用link的方式來關聯。這個是在直播裡面學到的瓦基使用link和connect的時機\n寫成文章時 把所有想到和這篇文章相關的卡片用bullet list 來link到entry card\n這個方法是從瓦基學到的，文章/keyword card/entry卡片上面先用link把所有相關的卡片給連結進來。再來在這張卡片下面開始書寫文章。\n這個方法的完全是利用了heptabase的功能。\n首先heptabase的list可以隨意拖拉，來初步排列出書寫的順序。這個在各大筆記軟體（notion、evernote等）上的bullet list 其實都可以做得到。 Open in new tab → 再點選所有的link，heptabase會在右邊打開所有卡片，這樣可以快速的複製卡片內容過來變成初稿。 這篇文章大致上描述了我現在會在heptabase上面實作的卡片筆記流程，並且這篇文章也是我第一次在heptabase上面使用卡片筆記寫成的。總共花了一個下午和半個晚上研究、半個晚上整理成文章。\n","date":"2022-09-03T23:18:17+08:00","permalink":"http://coding.fnsne.com/posts/%E6%88%91%E7%94%A8heptabase%E4%BE%86%E5%AF%A6%E4%BD%9C%E5%8D%A1%E7%89%87%E7%9B%92%E7%AD%86%E8%A8%98%E7%9A%84%E6%96%B9%E5%BC%8F/","title":"我用heptabase來實作卡片盒筆記的方式"},{"content":"問題描述 明明有開啟toc功能，但是在旁邊的toc卻完全沒有顯示任何的標題鏈接。\n解法 這個問題的原因很簡單，是因為LoveIt預設會抓h2的標題，但我習慣從h1的標題開始寫，所以在toc上面沒有任何的標題存在。\n解決的方法很簡單，只要到設定（config.toml）裡面，加上\n[markup] [markup.tableOfContents] startLevel = 1 即可讓LoveIt從h1就開始抓到toc上面。\nreference LoveIt Github Issue 410\n","date":"2022-09-02T16:06:28+08:00","permalink":"http://coding.fnsne.com/posts/hugo-loveit-%E4%B8%8D%E6%9C%83%E9%A1%AF%E7%A4%BA/","title":"Hugo LoveIt 不會顯示toc"},{"content":"描述 原本在hugo上面放文章是把所有的文章和圖片都放在content/posts/裡面用文章來分類。\ncontent/posts/ ├── post1 │ └── post1.md │ └── img1.jpg ├── post2 │ └── post2.md │ └── img2.jpg ├── post3 │ └── post3.md │ └── img3.jpg 因為覺得全部文章和圖片都放在一起是在是太過於雜亂，而且害怕未來文章多的時候，markdown和圖片的命名會很痛苦，雖然也是可以利用在前面加上日期前綴來區分，但感覺還是會很亂。所以開始研究page bundle怎麼處理,試著將結構改成這樣。\ncontent/posts/ ├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── post2 │ └── post2.md │ └── img2.jpg ├── 2022-09-02 │ └── post3 │ └── post3.md │ └── img3.jpg 問題 看到跑出來的網頁上，載入圖片404的網址居然是還會增加一個文章名稱的資料夾，然後才存取圖片。以上面的例子來看， 打開網頁 post1頁面，網址會是domain/posts/2022-08-02/post1/post1/\n而圖片是呼叫domain/posts/2022-08-02/post1/post1/img1.jpg\n可是實際上到build出來的public裡面去看，這一個頁面的結構居然是長這樣\n├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── post1 │ └── index.html 解法 因為查到的所有資料，上面寫的md都命名為index，所以試著把post1.md改名為index.md，一切就正常了，而此時public裡面的資料結構變成長這樣。\n├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── index.html 看起來可能是因為bundle是抓index.md這個關鍵字的來製作頁面，如果沒有這個檔案，會用現有的*.md的檔案，各自建立一個它名稱的資料夾，然後在裡面建立index.html。所以原本的做法才會長成奇怪的結構。\nreference hugo github上面討論bundle的issue Markdown 技術文件寫作-處理圖檔\u0026mdash;黑暗執行續 hugo官網 Page Bundle ","date":"2022-09-02T14:36:26+08:00","permalink":"http://coding.fnsne.com/posts/hugo-bundle%E5%95%8F%E9%A1%8C/","title":"Hugo  Bundle問題"},{"content":"最近開始使用Goland來用hugo寫部落格文章，之前markdown的preview分頁都還很正常，但到了今天，突然之間只剩下一般的編輯界面，而且Goland好像還把它識別為html,旁邊會出現在各種瀏覽器上面的按鈕。\n而且使用hugo的shortcode還會出現網頁相關的錯誤訊息，在設定裡面查了一陣子才發現到。關於檔案的偵測少了.md的部分，只剩下markdown的部分\n將*.md加上去，一切的紅底線、還有markdown就都全部回來了。\n","date":"2022-09-01T20:21:30+08:00","permalink":"http://coding.fnsne.com/posts/goland-markdown-split-editor%E6%B6%88%E5%A4%B1%E7%9A%84%E5%95%8F%E9%A1%8C/","title":"Goland Markdown split editor消失的問題"},{"content":"內文 最近在godaddy上面購買網域，然後使用cloudflare來申請ssl並弄成https的連線。結果今天上來看blog卻發現進不去，錯誤訊息是太多的redirect了。 打開F12重整看看，還真的是持續進行著\n經過一段研究，發現只是這個問題很sssssssss多人有遇到，只是因為CloudFlare的SSL設定設到了Flexible\n參考資料 {\u0026lt; link \u0026ldquo;https://community.cloudflare.com/t/error-301-on-dns-and-http-proxy/77699\" \u0026gt;}}\n","date":"2022-09-01T17:01:39+08:00","permalink":"http://coding.fnsne.com/posts/cloudflare_ssl_in_redirect_loop/","title":"CloudFlare SSL in redirect loop"},{"content":"從物件導向的語言轉到Golang常常會遇到，不知道該怎麼在Golang實作類似多型和繼承的功能。這是因為Golang根本不是物件導向的語言。\n在網路上會看到一些文章，寫說可以使用可以embed來模擬繼承，但事實上embed的用途應該只是用來減少重複的程式碼，增加可讀性。像在io package裡面就很明顯，如interface ReadWriter就是用Reader和Writer 兩個interface組合起來的。\ntype ReadWriter interface { Reader Writer } 使用embed struct的方式來模擬繼承。為了要可以被抽換注入，還是得要同時implement一個interface。這樣還不如直接implement interface就好了。\n在Golang，唯一類似物件導向的東西只有 interface。只要有implement interface，就可以在宣告使用這個interface的地方使用。\n個人的理解，Golang把繼承的概念且分成兩個部分：embed和interface。embed struct (interface) 負責擴增fields (method); interface負責讓不同struct可以有相同的調用方式\nembed struct 的功能只是單純消除struct的field的重用而已。embed interface 也是如此，單純想要減少 method 裡面重複宣告 method 的程式碼。\n簡單來說，就是\n想要可以抽換，用interface; 想要減少重複可以用embed的方式包裝組合\n","date":"2022-08-02T20:01:59+08:00","permalink":"http://coding.fnsne.com/posts/%E6%B7%BA%E8%AB%87%E5%9C%A8golang%E4%B8%8A%E9%9D%A2%E7%9A%84%E7%89%A9%E4%BB%B6%E5%B0%8E%E5%90%91/","title":"淺談在Golang上面的物件導向"}]