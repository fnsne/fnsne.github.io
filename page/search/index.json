[{"content":"排查問題的小技巧：假設 跟大家分享一下最近發現到，在debug時的一個小技巧\n先假設原因\n這個做法，其實是在我閱讀《雜訊時代的高效資料整理術：精準掌握二成黃金資訊的39個法則》 關於收集資訊的章節後，在工作上debug時突然靈機一動，亂套用看看\n結果發現還真的蠻好用的。\n這個做法其實很簡單，就是\n初步瞭解狀況\n假設一個發生的原因\n以假設的原因來設計重現步驟（比較小的部分，可以順便寫對應的測試來跑）\n嘗試看看能不能重現同樣的問題，如果不行就回到第二步，再改變假設\n就這樣!\n為什麼我會覺得這個方法很好用呢？\n因為我很常會在前面的階段花上過多的時間來分析和思考，導致很晚才開始碰code。\n但通常真正的問題得要獲得一些更內部的資訊才有可能察覺到， 而這些資訊，通常得要在實際嘗試後才有可能會得到。\n也就是說，在這樣快速假設→驗證的流程下，能夠讓我更快速的獲得比較深入的相關資訊，有了更多的資訊，就更有機會能分析找到問題的根源在哪裡。\n所以在套用了這個方法後，我debug的速度加快了不少，至少在找到原因的步驟，快了至少一倍\nP.S. 這樣就知道我以前多會在前面思考的部分糾結了……\n","date":"2024-11-18T21:43:53+08:00","permalink":"http://coding.fnsne.com/posts/debug-tricks-suppose/","title":"Debug的小技巧:假設"},{"content":"解決拖延症的方法 拖延症，是我們大部分的人都會遇到的問題。雖然之前有看到一種說法，「會拖延，只是因為對自己來說還不急，所以才會一直的拖延下去」。 但我常常發現，即使是對於我來說很重要的事情，就是不知道為什麼，即使已經切分好小小的行動了，還是無法下定決心來做。\n但是，在今天，我找到了一個方法，那就是：切成多個步驟，每個步驟只能用5分鐘，用多次迭代出結果出來。\n在《雜訊時代的高效資料整理術：精準掌握二成黃金資訊的39個法則》裡面有提到作者如何快速的做到收集資料、整理、輸出這三件事，\n那就是\n就是每件事只給一個番茄時間（25分鐘），一旦超過就要強制進入下一個階段。\n也就是25分鐘收集資料，25分鐘整理資料，25分鐘進行輸出。\n這樣做可以藉由限制時間來避免在每個階段的拖延。\n對我來說，番茄鐘算是很熟悉的東西，白天工作的時候常常會使用它來讓我保持最高的專注力。 但到了晚上，往往已經動力已經足以驅動我花一個番茄時間做事了。\n在這個時候，我回想到《專注力協定》裡面提到的10分鐘法則：\n「什麼都不要考慮，先做10分鐘再說」\n在這樣一來一回的調整後，就得到了一個適合我的方法了。\n把要做的事情分成多個步驟，每個步驟都給極短的時間，時間到就要進入下一個步驟。但可以重複好幾輪。\n這個做法極大的減少心理的阻力：\n因為知道這輪沒有做好，還可以用下一輪來做，讓自己接受產出不完整的結果，所以阻力會比較小。\n因為每個步驟的時間只有5分鐘，所以不會有任何思緒在胡思亂想。\n因為只有5分鐘，所以開始嘗試的阻力也會跟著小起來。\n結果套用它後，原本已經拖延了好幾天、遲遲無法有所進展的事情，今天終於又開始有所推進了。\n雖然之前在看《專注力協定》後，就開始嘗試使用timeboxing做事情，\n但後來發現timebox只是減少了分心去思考要不要做別的事情而已。 可是對於做timebox上定好的事情的阻力，還是一樣大。所以有時候就會變成，在定好的時間裡面發呆……\n現在加上了這個方法，應該能讓我更能掌握我的時間，做更多我想要做的事情。\n","date":"2024-11-15T00:27:17+08:00","permalink":"http://coding.fnsne.com/posts/solve-procrastination/","title":"解決拖延症的方法"},{"content":"我整理電子書highlight的方法：萃取階段 接續[上一篇]/posts/category-highlights/的內容 其實到了這個階段，就只剩下很簡單的行為了：就是利用碎片時間慢慢整理之前彙整好的知識點卡片了。\n步驟：\n篩選出還沒有消化好的知識點卡片 閱讀和整理知識點卡片 如果知識點卡片還可以延伸出其它的知識，那就產出來 把產生的知識點卡片給鏈接到主題分類上 詳細流程：\n步驟1: 篩選出還沒有消化好的知識點卡片 要做到這點其實很簡單，只要再多加上一個消化完成的tag來區分是否消化完成。就可以在Card Library上設定篩選器。\n也就是設定有reference tag，但不要有消化完成tag的卡片就可以了。\n設定如下圖：\n步驟2: 閱讀和整理知識點卡片 因為知識點卡片上面通常已經彙整了不少相關的資訊在上面了，在這個時候開始整理大多情況都會變得很快速順暢。\n可以從下圖看到，此時內容已經很充足，能讓我快速整理出通順內容了。（highlight來源：雜訊時代的高效資料整理術）\n步驟3: 如果知識點卡片還可以延伸出其它的知識，那就產出來 這一步，只有在發現卡片中其實還可以再次彙整出不同的知識點卡片時，才需要做。\n做法和[上一篇]/posts/category-highlights/的時候一樣， 就是從這張知識點卡片再分出不同的子知識點卡片出來。\n步驟4: 把整理完的知識點卡片的鏈接加到主題分類上 主題分類：是我從瓦基的卡片盒筆記實戰課裡面學到的一個很重要的東西，它上面列出我所在乎的所有主題。\n它是我的第二大腦最一開始的進入點。\n每當我想要找相關的主題內容的時候，可以從主題分類開始進入。讓我一邊閱讀尋找我要的知識，一邊把相關的知識給再看到一次。\n因為有主題分類的存在，讓我可以把我學到的知識點，和我至今所學的知識整理在一起，而不是依照書名、書目錄架構、課程的順序來排序\n有了主題分類，等於我能夠把所有我所學到的知識、想出來的點子，給連結起來。 即使未來忘記了，也還是可以從主題分類開始順藤摸瓜，慢慢找到我要的知識。\n而不會變成忘記關鍵字，就很有永遠找不到那張卡片了。\n放到主題分類的流程：\nCtrl+O 全局搜尋我的主題分類，來找到主題分類的卡片 找到和這個知識點卡片相關的主題，一層層的往下找， 直到找到有類似的知識點卡片鏈接，在它旁邊加上這張知識點卡片的鏈接。 例如下圖這是我的主題分類 → 生產力\u0026amp;時間管理主題的部分內容\n","date":"2024-11-14T00:49:22+08:00","permalink":"http://coding.fnsne.com/posts/extract-highlight/","title":"我整理電子書Highlight的方法：萃取階段"},{"content":"我整理電子書highlight的方法：彙整階段 接續上一篇的內容\n前面我有提到我使用readwise把highlight給同步到heptabase（筆記軟體）上面，所以當我標記完，highlight就會自動到heptabase上面了。\n接下來就是整理階段，我把整理階段分成兩個階段，這篇文章會著重在第一階段，彙整。\n彙整 簡單來說就是利用whiteboard和section功能，把感覺有相關概念的卡片放在附近，然後用section群組起來。最後再連結到一個萃取出來的卡片上面。\n在這個階段，我會在heptabase上面新增一個whiteboard，然後把它pin到左側的tab上。我是使用閱讀資料夾來分類的用來放置我還沒有整理完的書的whiteboard\n接下來我會再把彙整分成兩步驟：把類似的highlight放在附近、彙整出筆記粗稿\n步驟1: 把類似的highlight放在附近 在這個時候，我會打開kobo app，依照書本上的順序，重新閱讀highlights，並把我覺得重要的highlights放到whiteboard上面，把覺得類似的highlight放在一堆，然後用section群組起來。\n詳細的流程：\n一頁一頁的看kobo app上劃線的highlights，一邊思考這是否重要，重要的話，在heptbase上，搜尋對應的關鍵字，找到heptabase上對應的highlight卡片。把它移到whtieboard上面，其它和這張highlight相關的卡片的附近。 雖然有時候kobo送到readwise的順序怪怪的，但還是可以藉由使用highlight的搜尋功能，搜尋highlight的前幾個字。來做到以實際書本上面的highlight順序來截取highlights。\n發現某些相關的highlight有個可以總結他們概念的大標題時，把他們放在一起，然後使用section功能群組在一起。（多選卡片→Ctrl + G） (這是我閱讀《專注力協定》的時候做的whiteboard。) 步驟2: 彙整出筆記粗稿 在這個時候，重新以section為單位來閱讀highlights並參考section標題，彙總出筆記粗稿。\n詳細流程：\n打開whiteboard的右邊側欄，點Table Of Content 使用Table Of Content跳到各個section上，重新閱讀highlight，思考是否能彙整出什麼知識點，這個知識點就是筆記粗稿的標題\n如果有，就在section旁邊建立以該知識點為標題的卡片，並用copy content把相關的highlight內容貼到知識點卡片上。\n回到這些highlight上，在筆記的部分，連結這個知識點卡片。這樣未來就能使用卡片下方的backlink，來找到當初是由哪些highlight，來得到這個的知識點卡片的。\n到了這一步，畫面應該會長這樣\n在知識點卡片上，加上屬於知識點卡片的tag，我是使用reference。藉由這個讓我下一階段時，能只篩選出知識點卡片。 在這樣整理之後，我就可以把各種知識切成一塊塊小組，然後再下一階段的時候，利用碎片時間萃取了。\n備註 步驟2可以在任何時候做，可以在剛圈出一個section的時候馬上做，也可以等步驟3把整本書整理過之後，再來做。\n在上一篇文章提到的問題：Kobo即使是電子書閱讀器，有時候highlight也會斷掉。在這個做法下不會有問題，因為我在步驟2的時候，會一邊打開kobo app放在旁邊作為索引，用搜尋的方式在heptabase上查找highlights。所以即使我沒有讓一整段highlight在一起，而是切成好幾段標記，也還是可以找到應該要連在一起的highlights。\n","date":"2024-11-11T00:23:33+08:00","permalink":"http://coding.fnsne.com/posts/category-highlights/","title":"我整理電子書Highlight的方法：彙整階段"},{"content":"我覺得電子書真的是劃時代的發明 接下來幾天，我會分享我最近發現到，很好閱讀電子書的方式，今天先來分享閱讀電子書的好處。\n電子書的highlight功能真的是劃時代的設計，因為現今大部分的電子書都有提供把highlights給匯出的功能。\nhighlight是什麼？其實就是像在紙本書籍上，拿起熒光筆把重點畫起來。 但重點是，電子書是數位的，所以能夠把highlight給整理成筆記的粗稿，光是這個流程就能讓閱讀學習的效率變得飛快。\n也就是說：\n我們在閱讀的時候只需要把覺得有道理、不懂的名詞解釋、新的流程等文字，劃線起來，就能繼續往後閱讀。\n不會有糾結要不要寫筆記，也不會因為寫筆記而導致閱讀的注意力被中斷掉。因為我們都有把重點給畫下來了。\n電子書的劃線功能讓我們能分割閱讀和筆記這兩件事情。\n接下來來說明一下我使用過的電子書：kindle、kobo、博客來的電子書。還有後來為何我選擇kobo\n博客來電子書 它的highlight匯出功能我記得只能一個個highlight匯出，所以在我知道highlight這個超級好用的功能之後，我就放棄這個平臺了。\nKindle 它的使用體驗是最好的，手機上的電子書閱讀器app，劃線功能非常的好操作，即時會需要跨頁highlight，使用起來也非常的順暢，並且不會有畫錯的問題發生。 而highlight的匯出能一次匯出來、也可以使用Readwise同步到筆記app上。缺點就是highlight有限制字數，不能超過該本書的10%。還有中文書的價格都偏高。\nKobo 建議一定要買電子書閱讀器來使用，因為它的app畫highlight功能不支援跨頁。\n所以使用手機版app就別想要做highlight了。 而且手機版還額外有個bug，常常選取了一段話，最終標記出來的段落有時候會變成中間的幾個字，而不是一開始選取的字。\n因此如果要使用app的話，只會建議使用電腦版kobo app，因為版面比較足夠，而且劃線不會有手機版的亂截取bug。 但即使版面較大，還是有機會會遇到需要跨頁截取的情況，這個時候，就只能一直切換字體大小，直到想要截取的畫面在同一個版面上。\n再來就是kobo電子書的價格，每週都會寄當週每天特價99的書籍， 而且常常會有週末閱讀好時光，也就是在週末的時候，訂單超過一定價格，會送111點點數，在kobo裡面，1點點數等於1元，所以就能買更多書了。\n這點真的是非常的香。\n再來說說kobo出的電子書閱讀器，使用體驗就是中規中矩了。但它劃線支援跨頁，雖然有時候遇到特殊的排版時，例如列點之類的，就有可能會中間被斷掉。 不過因為我後續還會打開app在旁邊，然後在筆記本上整理，所以即使highlight是分段，而不是畫一整段，也沒有什麼問題。\n最後再說一次各家電子書的優缺點 博客來\n缺點：highlight匯出得要一個個highlight慢慢匯出，很麻煩 kindle\n缺點：\nhighlight有限制不能超過書字數的10%、書本價格偏貴。 優點：\n使用者體驗最好，不論是app還是kindle閱讀器，劃線畫到哪就真的畫到哪\n支援Readwise同步highlight\nkobo\n缺點：\n電腦app和手機app劃線不支援跨頁\n手機app常常會斷字\n電子書閱讀器劃線偶爾會抽風。\n優點：\n電子書常常會有優惠價99元\n常常就會有週末優惠，買書超過指定金額會加碼送購書點數。\n支援Readwise同步highlight\n雖然kindle的使用體驗最好，但最後我還是選擇了kobo，因為價格實在是太香了，並且highlight沒有限制字數。\n順帶一題，我用readwise自動把highlight給匯入到我的筆記軟體，heptabase。\n下篇文章再來分享如何整理highlight。\n","date":"2024-11-08T22:41:41+08:00","permalink":"http://coding.fnsne.com/posts/e-book-is-an-amazing-invention/","title":"電子書真的是劃時代的發明"},{"content":"關於Asynchronous Request Asynchronous Request（非同步請求），就是讓server收到請求後，馬上回應使用者有接收到了，但結果會等到執行完後再通知使用者。\n就像寄信一樣，寄出後我們就不用一直在郵局等，等到信件寄到目的地後，才能離開郵局。我們只要做了寄信的動作，就可以離開郵局做其它事情，郵局自然會把信件送達到目的地。 非同步請求也是這樣，在發出request後，server在收到請求後，就會把工作交由背景執行的worker進行運算，並在此時就告知使用者，讓使用者知道server已經收到要求了。\n所以使用者不會感覺到服務被卡住。\n最近我就有切身體驗到使用非同步請求對使用者體驗有著巨大的提升。\n那就是7-11賣貨便\n7-11賣貨便其實每逢節慶，就會開始發放優惠券、折價券，但很常見的發放時間都是在半夜12點的時候開始，因此每到那個時候整個賣貨便服務就會變得非常的卡頓， 甚至會看到服務目前無法使用的訊息出現。\n為什麼我會知道這個呢？因為我的家人習慣使用賣貨便的服務來買東西， 所以每次到了這個時候，都會動員全家人想辦法領取優惠券。甚至到後來因為有時候會領取不到， 開始會定半夜2點的鬧鐘起來，在那個時候再領取優惠券。\n但就在最近\n在11-06的要領取雙十一的優惠券的時候，突然發現，領取優惠券的操作，變得十分的滑順。\n仔細一看發現，在按領取後畫面上很快就顯示「已進行領取，優惠券稍後會轉入帳號中」（之類的訊息），並且有個幾秒鐘的讀秒，然後重整頁面，優惠券就到帳了。\n這整個讓使用者體驗變得非常的好，因為使用者馬上就知道自己有領取到了，所以這就減少了非常多的使用者按F5的行為。\n再加上按了領取後，畫面上會有個讀秒的動畫，這和轉圈圈的動畫不同，因為這是已經收到回應了， 也就是說已經告訴使用者，你已經領取到了，只是我們還在跑程序，所以使用者比較不會在這個等待的時間中一直按F5。 在這一套修改下，讓我家人瘋狂稱讚，稱讚現在領取變得好快速。也讓他們不再在半夜起床領取優惠券。\n對於需要長時間運算的操作，很多時候其實可以嘗試使用Asynchronous Request，在增加使用者體驗的同時，也減少使用者等的不耐煩一直按重整導致的request數量。\n","date":"2024-11-07T20:59:16+08:00","permalink":"http://coding.fnsne.com/posts/asynchronous-request/","title":"Asynchronous Request"},{"content":"PREP輸出框架 PREP框架是一種輸出框架，它能夠協助我們快速的整理出一個有邏輯，又很好理解的文章。\nPREP分別是Point（結論）、Reason（理由）、Example（範例）、Point（再次重複結論）。也就是說，一開始的時候就先點題，把結論給寫出來。再來開始開始說明下這個結論的理由是什麼，然後舉例子。最終再次重複結論。在使用這樣的結構下，能夠很快速的讓人理解結論是什麼。 但使用PREP輸出框架需要注意，必須是在閱讀者已經瞭解前提和背景的情況下才能使用。如果閱讀者本身並未已瞭解前提、和背景，在這個時候就先點題，就反而容易讓人一頭霧水，不知道在說什麼。\n但如果在正確的對象上使用PREP，它就能讓我們在最短的時間內，整理出一個邏輯通順，很好理解的文字，快速的傳達出想要表達的內容。\n","date":"2024-11-05T22:13:15+08:00","permalink":"http://coding.fnsne.com/posts/prep-output-framework/","title":"PREP輸出框架"},{"content":"關於GeoJSON GeoJSON是一種基於JSON的地理空間數據交換格式，它定義了幾種類型JSON對象以及它們組合在一起的方法，以表示有關地理要素、屬性和它們的空間範圍的數據。 一個GeoJSON對象可以是Geometry, Feature或者FeatureCollection\nGeometry 支援 OpenGIS 簡式特性實作所定義的類型 : Point、LineString、Polygon、MultiPoint、MultiLineString、MultiPolygon 和 GeometryCollection\n格式範例如下\n{ \u0026#34;type\u0026#34;: \u0026#34;Linestring\u0026#34;, \u0026#34;coordinates\u0026#34;: [ [10.0, 11.2], [10.5, 11.9] ] } Feature 由Geometry加上部分屬性組成。 部分屬性類似於形狀檔，可包括形狀的屬性或 Placemarks 的 KML 資料夾\n格式範例如下\n{ \u0026#34;type\u0026#34;: \u0026#34;Feature\u0026#34;, \u0026#34;geometry\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [10.0, 20.0] }, \u0026#34;properties\u0026#34;: { \u0026#34;signpost\u0026#34;: \u0026#34;5\u0026#34;, \u0026#34;last_check\u0026#34;: \u0026#34;20200701\u0026#34; } } FeatureCollection 簡單來說，就是用來放複數Feature的JSON結構（Feature List）\n{ \u0026#34;type\u0026#34;: \u0026#34;FeatureCollection\u0026#34;, \u0026#34;features\u0026#34;: [ { \u0026#34;type\u0026#34;:\u0026#34;Feature\u0026#34;, \u0026#34;geometry\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [10.0, 5.0] }, }, { \u0026#34;type\u0026#34;: \u0026#34;Feature\u0026#34;, \u0026#34;geometry\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;LineString\u0026#34;, \u0026#34;coordinates\u0026#34;: [ [10.2, 1.0], [10.3, 2.0], [10.4, 2.5] ] }, \u0026#34;properties\u0026#34;: { \u0026#34;route\u0026#34;: \u0026#34;341A7\u0026#34;, \u0026#34;class\u0026#34;: \u0026#34;local\u0026#34; } } ] } ref https://zh.wikipedia.org/zh-tw/GeoJSON https://www.ibm.com/docs/zh-tw/db2/11.5?topic=formats-geojson-format ","date":"2024-11-04T21:28:29+08:00","permalink":"http://coding.fnsne.com/posts/geo-json/","title":"GeoJSON"},{"content":"淺談責任鏈（Chain of Responsibility）和裝飾器（Decorator）模式的差別 裝飾器模式和責任鍊模式，都是很常見用來把程式碼邏輯切開，讓不同元件能更明確用code表達其負責的邏輯的方法。\n以下先簡單介紹一下這兩種模式\n責任鏈模式（Chain of Responsibility） 接收輸入物件並沿鏈傳遞請求，直到其中一個handler處理它為止。 從重構的角度來看，當發現code的邏輯可以被切成不同的角色負責的邏輯時，可以重構成責任鍊的形式，分成不同的角色Class，讓各自的邏輯交由不同角色Class來處理。\n範例 要實作一個HandlerRequest，它可以處理Auth, Log, Data三種類型的Request 使用的時候要像下面例子這樣使用。\nfunc main() { req1 := \u0026amp;Request{Type: \u0026#34;Auth\u0026#34;, Payload: \u0026#34;User credentials\u0026#34;} req2 := \u0026amp;Request{Type: \u0026#34;Log\u0026#34;, Payload: \u0026#34;User activity\u0026#34;} req3 := \u0026amp;Request{Type: \u0026#34;Data\u0026#34;, Payload: \u0026#34;User data\u0026#34;} fmt.Println(HandleRequest(req1)) fmt.Println(HandleRequest(req2)) fmt.Println(HandleRequest(req3)) } 未使用責任鍊模式的HandlerRequest func HandleRequest(request *Request) string { if request.Type == \u0026#34;Auth\u0026#34; { return fmt.Sprintf(\u0026#34;Handling authentication: %s\u0026#34;, request.Payload) } else if request.Type == \u0026#34;Log\u0026#34; { return fmt.Sprintf(\u0026#34;Logging data: %s\u0026#34;, request.Payload) } else if request.Type == \u0026#34;Data\u0026#34; { return fmt.Sprintf(\u0026#34;Processing data: %s\u0026#34;, request.Payload) } else { return fmt.Sprintf(\u0026#34;Unknown request type: %s\u0026#34;, request.Type) } } 使用責任鏈模式的HandlerRequest 要先定義interface \u0026amp; Base struct\n// Handler 定義處理器接口 type Handler interface { Handle(request *Request) string } // BaseHandler 實作責任鍊的pass邏輯 type BaseHandler struct { next Handler } //只在其他Handler的Constructor中使用 func (h *BaseHandler) setNext(next Handler) { h.next = next } func (h *BaseHandler) handleNext(request *Request) string{ if h.next != nil { return h.next.Handle(request) } return \u0026#34;\u0026#34; } 接著實作AuthHandler, LogHandler, DataHandler\nAuthHandler:\n// AuthHandler 處理認證請求，並且有自己的參數 type AuthHandler struct { BaseHandler authKey string } func NewAuthHandler(authKey string, next Handler) *AuthHandler { handler := \u0026amp;AuthHandler{ authKey: authKey, } handler.setNext(next) // 設置下一個處理器 return handler } func (h *AuthHandler) Handle(request *Request) string { if request.Type == \u0026#34;Auth\u0026#34; { return fmt.Sprintf(\u0026#34;Handling authentication with key: %s, Payload: %s\u0026#34;, h.authKey, request.Payload) } else { return h.handleNext(request) } } LogHandler:\n// LogHandler 處理日誌請求，並且有自己的參數 type LogHandler struct { BaseHandler logLevel string } func NewLogHandler(logLevel string, next Handler) *LogHandler { handler := \u0026amp;LogHandler{ logLevel: logLevel, } handler.setNext(next) // 設置下一個處理器 return handler } func (h *LogHandler) Handle(request *Request)string { if request.Type == \u0026#34;Log\u0026#34; { fmt.Sprintf(\u0026#34;Logging at level: %s, Payload: %s\u0026#34;, h.logLevel, request.Payload) } else { return h.handleNext(request) } } DataHandler:\n// DataHandler 處理數據請求，並且有自己的參數 type DataHandler struct { BaseHandler dataSource string } func NewDataHandler(dataSource string, next Handler) *DataHandler { handler := \u0026amp;DataHandler{ dataSource: dataSource, } handler.setNext(next) // 設置下一個處理器 return handler } func (h *DataHandler) Handle(request *Request) string { if request.Type == \u0026#34;Data\u0026#34; { return fmt.Sprintf(\u0026#34;Processing data from source: %s, Payload:%s\u0026#34;, h.dataSource, request.Payload) } else { return h.handleNext(request) } } 最後，在main()需要多加上把不同的handler串成一個鍊（這邊是使用constructor注入的方式設定）\nfunc main() { // 初始化處理器 authHandler := NewAuthHandler() logHandler := NewLogHandler(authHandler) dataHandler := NewDataHandler(logHandler) // 創建請求 req1 := \u0026amp;Request{Type: \u0026#34;Auth\u0026#34;, Payload: \u0026#34;User credentials\u0026#34;} req2 := \u0026amp;Request{Type: \u0026#34;Log\u0026#34;, Payload: \u0026#34;User activity\u0026#34;} req3 := \u0026amp;Request{Type: \u0026#34;Data\u0026#34;, Payload: \u0026#34;User data\u0026#34;} // 處理請求 fmt.Println(authHandler.Handle(req1)) fmt.Println(authHandler.Handle(req2)) fmt.Println(authHandler.Handle(req3)) } 這樣做的優勢是，如果要修改Auth相關的邏輯，只要到AuthHandler去改即可。\n如果沒有使用責任鏈，當HandlerRequest內部使用的handler數量變得很大，並且決定要不要使用某個handler的邏輯很複雜時，邏輯甚至會互相糾結，讓code就會變得非常的難修改和維護。\n裝飾器模式（Decorator） 在現已有的邏輯上，外掛上額外的邏輯。\n範例 一樣是上面的requestHandler，但現在要加上一個額外的功能：不論處理成功或失敗，都要把結果記錄寫成log。\n這個外掛的功能就可以用decorator來實作，它並不會影響到核心功能，只是額外加其它功能上去。\n// LogDecorator 處理數據請求，並且有自己的參數 type LogDecorator struct { BaseHandler } func NewLogDecorator(next Handler) *DataHandler { handler := \u0026amp;LogDecorator{} handler.setNext(next) // 設置下一個處理器 return handler } func (h *LogDecorator) Handle(request *Request) { if h.handlerNext(request) != \u0026#34;\u0026#34; { log.Info(\u0026#34;request success\u0026#34;) }else{ log.Info(\u0026#34;request failed\u0026#34;) } } 結論 從實作方面來看，責任鏈和裝飾器的code是大同小異，都是藉由實作相同的interface，把多個邏輯拆分到不同的物件上處理。最後把Object依照順序一層層的注入到其它Object上，形成一個執行的鏈。它們唯一的差別是兩者切分邏輯的方式。\n責任鏈是鏈上的每個Object都能獨立完成一種使用情境的邏輯；而裝飾器則是為核心邏輯外掛其它額外的功能。\n當有核心功能存在，需要外掛附加功能時，這個做法就可以稱為裝飾器模式；而當有不同的handler， 並且每個都可以獨立處理完某一種使用情境時，就稱其為責任鏈模式。一切都是看想要切分的邏輯，是切出核心邏輯和外掛邏輯（裝飾器）， 還是切出不同的職責，每個都是一種情境的核心邏輯（責任鏈）。他們的形式可以長得一樣，差別只在於他們切分產生出來的handler能否獨立完成一種工作。\n資料來源 https://coderanch.com/t/668194/certification/Difference-Decorator-Chain-Responsibility-patterns ","date":"2024-11-03T21:37:26+08:00","permalink":"http://coding.fnsne.com/posts/decorator-vs-chain-of-responsibility/","title":"關於裝飾器模式和責任鏈模式"},{"content":"淺談Golang Generic 泛型 什麼是泛型？ 泛型（Generic）是一種用來協助製作通用function、struct用的功能。 在泛型還沒有支援之前，要製作通用的function、stuct，通常就只能在輸入、輸出的地方使用interface{}結構。 而且這樣做需要很小心的檢查使用是的形態是否正確。\n在function參數上使用泛型 在使用泛型之前，我們會使用interface{}來製作通用function\n例如：\nfunc Add(a, b interface{}) interface{}{ switch a.type{ case int: return a.(int) + b.(int) case float32: return a.(float32) + b.(float32) default: panic(\u0026#34;not support type\u0026#34;) } } 但是這樣每次要增加新的可以接受的結構時，就再需要增加不少的檢查code。而在有了泛型以後，這段的檢查，就可以交由編譯器來處理了。 就可以變成以下這樣\nfunc Add[T int|float32](a, b T) T{ return a + b } //調用時如下 Add[float32](1.1, 2,2) 即使未來有需要再增加支援int64形態，也只需要在中括號中再加上即可。\nfunc Add[T int|float32|int64](a, b T) T{ return a + b } 在struct上使用泛型 泛型也支援在struct上面使用。\n以下的例子是在定義API回傳JSON格式時，不論什麼情況，都需要擁有Code, Params, Data這三個Field，而Data才是用來放置該API的回傳值。 但要做到這樣，等於每個module中，都要重新再定義一次，確實很惱人。\n後來公司同事想到可以利用泛型，來定義出通用的回傳框架，只要使用這個struct，就可以產出有基本結構的struct出來。\ntype DataResponse[T any] struct{ Code string `json:\u0026#34;code\u0026#34;` Params []string `json:\u0026#34;params\u0026#34;` Data T `json:\u0026#34;data\u0026#34;` } 這樣以後要定義回傳結構時，就不用每次重複定義Code和Params了\ntype User{ Name string Avatar string } type DataResponse[User] GetUserResponse 總結 泛型的使用情境，是用來製作通用struct、通用function時使用的。 例如：通用的回傳結構、通用的資料結構（如Stack）。 但對我個人而言，我很少用到它，因為目前工作上面，我都是在做應用層面的功能開發，而不是寫Library。大部分需要用抽象整合起來的地方，都是使用interface來抽的。 幾乎沒有機會遇到必須使用泛型的情況，所以我對於泛型的認知也只到這邊而已。\nref https://www.digitalocean.com/community/tutorials/how-to-use-generics-in-go#go-collections-with-generics https://go.dev/doc/tutorial/generics ","date":"2024-11-02T22:59:36+08:00","permalink":"http://coding.fnsne.com/posts/golang-generic/","title":"關於Golang的泛型"},{"content":"探討在Golang_gorm上使用樂觀鎖的做法 在Gorm上如果要使用Optimistic locking的話，使用go-gorm optimisticlock會是一個好選擇。因為它只需要在Model定義好，就可以正常使用了。可以避免實作的時候忘記加上WHERE version = ?的條件。而變成沒有使用樂觀鎖保護資料的情況。\n為什麼要使用樂觀鎖？ 樂觀鎖實際上是沒有使用到Lock的，所以在沒有衝突的情況下，每筆資料的更新速度，會比有使用Lock的情況還要快速。 所以在資料庫更新頻率較低的時候，樂觀鎖是一個不錯的選擇。 樂觀鎖的缺點是，如果有兩個人同時更新同一筆資料，就會有一個人的更新會失敗。這時候就需要重新讀取資料，再重新更新一次。所以不適合在資料更新頻率很高的情況下使用。\n另一方面，在產品還在MVP階段的時候，重點是趕快把Business Model 實作出來放到市場上，看看市場反應如何。能儘量快一點把功能做出來會越好。等確定這個功能是真的有市場，再來考慮優化效能方面的問題。 使用樂觀鎖+ORM，能簡化開發要寫的code，因為使用樂觀鎖+OR，就能讓大部分的code都變成，取出該筆資料-\u0026gt;更新欄位的值-\u0026gt;整筆存起來，並且可以避免資料更新的時候，用到別人更新的資料（race condition）， 這樣幾乎每個table就只需要有Get、Update就能完成所有更新的操作了。因此在MVP階段，使用樂觀鎖是一個不錯的選擇。\n以下列出各種寫法，就能很清楚的看出來使用樂觀鎖的好處，還有為什麼要使用Optimisticlock套件了。\n範例 table books table 欄位有 id, title, count, updated_at; 每賣出一本書，就要讓count加1。 請實作出AddBookCount的方法。\n方法1：使用Atomic Update 剛好這個例子只需要更新一個欄位的值，所以可以使用Atomic Update來實作。但在一些複雜的情境下，並不是單純的對原本的數值做加減的情況，就不能使用這個方法，而是需要使用下面其它的方法了。\ntype BookRepo struct{ db *gorm.DB } func (repo* BookRepo) AddBookCount(bookID string, count int) error { err := repo.db.Model(\u0026amp;Book{}). Where(\u0026#34;id = ?\u0026#34;, bookID). Update(\u0026#34;count = count + ?\u0026#34;, count). Update(\u0026#34;updated_at\u0026#34;, time.Now()). Error if err != nil { return err } return nil } 方法2：使用lock 這個做法，在大部分的情況下可以正常運作。（例外：Phantom Read, Write Skew的情況)。\ntype BookRepo struct{ db *gorm.DB } func(repo* BookRepo) AddBookCount(bookID string, count int) error{ tx := repo.db.Begin() //lock the book record var b Book err := tx.Clauses(clause.Locking{Strength: \u0026#34;UPDATE\u0026#34;}).Where(\u0026#34;id = ?\u0026#34;, bookID).First(\u0026amp;book).Error if err != nil{ tx.Rollback() return err } //update the book record b.Count += count err = tx.Save(\u0026amp;b).Error if err != nil{ tx.Rollback() return err } tx.Commit() return nil } 方法3：使用樂觀鎖 雖然看起來都有點複雜，但只要是針對一個record的更新，都可以簡化成同樣的流程：取出該筆資料-\u0026gt;更新欄位的值-\u0026gt;整筆存起來。這樣在一些比較複雜的情境裡面，就可以用相對簡單的方式實作出來。\n用UpdatedAt來自己實作 常見的做法，使用updated_at欄位來做為樂觀鎖的版本號，但這個方法有一個缺點：如果更新在比updated_at記錄的時間顆粒度還小的時間內一起發生，就會發生問題。例如updated_at的顆粒度是秒，但有多個request在同一秒內更新，就會相撞。 所以這個做法要很小心，注意更新的頻率和updated_at資料的顆粒度。但通常來說，如果更新頻率偏高，通常就會開始改成使用Lock的方式，而不是樂觀鎖了。\ntype BookRepo struct{ db *gorm.DB } func(repo* BookRepo) AddBookCount(bookID string, count int) error{ //lock the book record var b Book err := tx.First(\u0026amp;book, \u0026#34;id = ?\u0026#34;, bookID).Error if err != nil{ return err } //update the book record b.Count += count err := tx.Model(\u0026amp;Book{}).Where(\u0026#34;updated_at = ?\u0026#34;, b.UpdatedAt).Updates(\u0026amp;b).Error if err != nil{ return err } //檢查是否成功更新 if tx.AffectedRows() != 1{ return errors.New(\u0026#34;更新失敗\u0026#34;) } return nil } 用Version欄位來自己實作 能避免上面用updated_at來實作樂觀鎖提到的缺點。但是必須要在欄位上，多加上一個version的欄位\ntype BookRepo struct{ db *gorm.DB } func (repo* BookRepo)AddBookCount(bookID string, count int) error{ var b Book err := repo.db.First(\u0026amp;b, \u0026#34;id = ?\u0026#34;, bookID).Error if err != nil{ return err } b.Count += count currentVersion := b.Version b.Version += 1 err = repo.db.Where(\u0026#34;version = ?\u0026#34;, currentVersion).Updates(\u0026amp;b).Error if err != nil{ return err } // 檢查是否成功更新 if repo.db.RowsAffected != 1{ return errors.New(\u0026#34;更新失敗\u0026#34;) } return nil } 使用go-gorm/optimisticlock 在Model使用optimisticlock.Version\ntype Book struct{ ID string Title string Count int UpdatedAt time.Time Version optimisticlock.Version } type BookRepo struct{ db *gorm.DB } func (repo* BookRepo)AddBookCount(bookID string, count int) error{ var b Book err := repo.db.First(\u0026amp;b, \u0026#34;id = ?\u0026#34;, bookID).Error if err != nil{ return err } b.Count += count err = repo.db.Save(\u0026amp;b).Error if err != nil{ return err } // 檢查是否成功更新 if repo.db.RowsAffected != 1{ return errors.New(\u0026#34;更新失敗\u0026#34;) } return nil } 完整範例在此\n結論 使用Atomic Update的方式，速度最快，但不一定適用於所有的情況。 使用Lock的方式，能夠避免race condition的發生，但因為要取得、釋放lock，所以每個request執行所需要的時間會比較長一些。當然，在更新頻率較高的情況下，多等一下下，總是比全部重新來過還要快。 如果要在Gorm上使用樂觀鎖，這個時候使用樂觀鎖套件會比較好，因為不論是哪種自己實作的樂觀鎖，都會需要多加一些檢查的條件，但在使用樂觀鎖套件的時候，只需要在Model上加上optimisticlock.Version，剩下的就是照常的使用Gorm的方法就好了。 ","date":"2024-11-01T13:42:30+08:00","permalink":"http://coding.fnsne.com/posts/golang-gorm-optimistic-lock/","title":"探討在Golang_gorm上使用樂觀鎖的做法"},{"content":"1. 安裝certbot sudo apt install certbot 2. 使用certbot申請SSL憑證 手動驗證（manual) sudo certbot certonly -d \u0026lt;DOMAINNAME\u0026gt; --manual certonly：表示只需要申請憑證即可。certbot還有支援一些常見的server替換SSL的功能，如apache、nginx等 --manual：表示要使用互動界面來申請憑證。 注意：使用\u0026ndash;manual的方式申請的憑證，除非有配合使用其它驗證插件，否則無法自動renew。\n這個方式申請的憑證有提供兩種預設方式驗證\n會產生一個challenge檔案，然後讓我們放到要使用這個憑證的機器（至少是這個domain name會連到的機器）的根目錄下指定的資料夾，讓ACME驗證可以使用申請的domain name加上給定的ACME資料夾，拿到申請的檔案。 直接會在目標機器上加上一個短暫的server，做到在指定的網址回傳上述的challenge檔案。 另外certbot其實還提供了其它的驗證方式，例如DNS\nsudo certbot certonly -d \u0026lt;DOMAINNAME\u0026gt; --preferred-challenges dns --manual certbot會在申請的互動界面，產生一個申請憑證網域的challenge key和value，申請人要到DNS託管服務，例如GoDaddy、AWS Route53等服務上，對要申請憑證的網域使用certbot產出的key value來建立一筆TXT設定，讓Let’s Encrypt確定要申請的網域是屬於你的。 使用Route53插件驗證 其實就是藉由Route53的API，讓插件替我們做完把ACME Chellenge TXT設定到DNS Server上的這段流程。所以需要設定AWS的access client到申請憑證的機器上。\n1. 安裝certbot-dns-route53 sudo apt install python3-certbot-dns-route53 其它plugin的名稱也是使用相同的pattern: python3-certbot-dns-\u0026lt;PLUGIN\u0026gt;\n2. 設定AWS的access client 到AWS設定一個Policy { \u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;certbot-dns-route53 sample policy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53:GetChange\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] }, { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;route53:ChangeResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34; : [ \u0026#34;arn:aws:route53:::hostedzone/YOURHOSTEDZONEID\u0026#34; ] } ] } Version的值不能改，這是告訴AWS要用這版的規則來看這個Policy\nYOURHOSTEDZONEID：去Route53點選要設定的domain name，就會寫出它的host zone ID（託管區域ID）了。\n建立一個IAM account，並且授予它上面的policy權限\n在要執行certbot的機器上建立一個config檔，叫~/.aws/config內容如下\n[default] aws_access_key_id=\u0026lt;IAM的ID\u0026gt; aws_secret_access_key=\u0026lt;IAM的secret key\u0026gt; 注意，如果執行certbot需要使用sudo來執行，這個config必須改放到/root/.aws/config。\n執行certbot sudo certbot certonly --dns-route53 -d rd2.team.araliadata.io 如果有要申請wildcard網域，需要多加上*.rd2.team.araliadata.io才需要有這段\n—-post-hook：當certbot完成執行後，會在本地執行的動作。\n設定排程執行sudo certbot renew，它會自行檢查是否有憑證快要到期了，如果快要到期才會真的再次申請新的憑證下來。 sudo certbot renew --cert-name \u0026lt;憑證名稱\u0026gt; --post-hook \u0026#34;docker compose -f /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml down \u0026amp; /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml up -d\u0026#34; 憑證名稱：可以使用certbot certificates來查看\ncertbot renew：當憑證會在30天內到期時，真的去申請新的憑證，還未到期不會真的去申請新的憑證。\nex: 每週一檢查一次\n#sudo crontab -e 0 0 * * 1 sudo certbot renew --cert-name rd2.team.araliadata.io --post-hook \u0026#34;docker compose -f /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml down \u0026amp; /home/bigobject/data-planet-testbed/ambrose/docker-compose.yml up -d\u0026#34; 提醒 可以先加上 --dry-run ，用來測試server申請憑證是否能成功，以防操作太多次，超過額度，不給申請。\n使用--manual的憑證申請，不能使用renew功能，除非有加上authentication hook，例如上面提到的route-53 plugin。\nroute-53 plugin其實就是用script連到route-53服務，新增對應的ACME challenge TXT。\nACME的驗證（--preferred-challenges），如果選擇使用DNS的方式驗證，需要使用--manual才能做。除非加上DNS插件驗證（如route53）。\n","date":"2024-07-04T21:09:08+08:00","permalink":"http://coding.fnsne.com/posts/certbot_auto_gen_ssl_certificate/","title":"如何用certbot申請 Let’s Encrypt 的憑證"},{"content":"在乾淨環境建立k8s環境 使用k8sadmin架設k8s環境\nlinux環境設定 在開始安裝之前，需要先把host給設定好，所以會先說明要做哪些動作。\n關閉swap功能 關閉swap swapoff -a 編輯 /etc/fstab vim /etc/fstab 把檔案裡面 /swapfile 開頭的這行註解掉\n安裝docker 安裝所需的工具 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install ca-certificates curl gnupg lsb-release 下載docker並新增官方的GPG key sudo mkdir -m 0755 -p /etc/apt/keyrings \u0026amp;\u0026amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 設定放docker的repository echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 安裝docker engine sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 測試有沒有成功安裝docker engine sudo docker run hello-world 調整權限，這樣以後就不需要每個docker command前面還要加sudo了。 sudo usermod -aG docker $USER 安裝apt-transport-https、ca-certificates、curl sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl 加上 Kubernetes apt 的repo 下載google cloud public signing key sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg 加上 apt 的repo echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list 安裝k8s環境執行用的工具 更新apt並安裝kubeadm, kubectl, kubelet，並鎖定版本 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y kubelet kubeadm kubectl \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubeadm kubectl 安裝cri-dockerd Container Runtime Interface (CRI)：Kubelet會使用CRI 界面來建立container。\n到cri-dockerd的repo上面，release找到對應的版本。複製下載鏈接，使用wget在機器上面下載下來\n例如ubuntu的\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.1/cri-dockerd_0.3.1.3-0.ubuntu-jammy_amd64.deb sudo dpkg -i cri-dockerd_0.3.1.3-0.ubuntu-jammy_amd64.deb 檢查有沒有安裝成功並跑起來 sudo systemctl status cri-docker.socket 啟動k8s cluster 如果有需要的話，可以使用kubeadm init -h看看，上面有更多資訊可以看\n使用kubeadm建立cluster sudo kubeadm init {options} 常見的options有 \u0026ndash;pod-network-cidr 希望給pod的網段例如：10.244.0.0/16。要注意，如果和要使用的CNI的預設不一樣，到時候得要在CNI上面設定一下。\n\u0026ndash;apiserver-advertise-address 來指定api server的網址，如果沒有設定，會使用預設的$網路$ 界面。\n\u0026ndash;apiserver-bind-port apiserver的port，預設是6443\n-apiserver-bind-port int32 Default: 6443Port for the API Server to bind to. (View Source)\n\u0026ndash;service-cidr 來指定service到時候被產生出來的virtual ip的range\n可以使用--cri-socket={CRI的socket}指定特定的cri 例子 sudo kubeadm init --pod-network-cidr 192.167.0.0/16 --cri-socket unix:/var/run/cri-dockerd.sock --service-cidr 192.168.192.0/18 做錯了可以使用kubeadm reset來關閉剛剛啟動（或者失敗）的k8s cluster。 讓現在的帳號可以使用kubectl 最後為了讓現在的帳號可以使用kubectl，而不是使用root帳號，需要做以下的操作\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 安裝CNI Container Network Interface(CNI)\n功能：\n負責container之間、還有對外的各種溝通\n負責創建、回收container時，用到的Network的功能。\n常見的CNI Flannel(已停止維護)、 安裝Flannel的方法：\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Calico。 安裝Calico的方法：\n下載yaml檔 wget https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml 安裝並啟動 kubectl apply -f calico.yaml 以上就完成了在Linux上架好一個k8s環境的controller plane (k8s叢集的master)了。但是這個時候還沒辦法在k8s環境裡面，在預設的情況下，controller plane所在的host會有設定一個汙點（類似tag的東西），不讓任何非系統運行是所需的Pod（k8s運行的基本單位）被啟動起來。所以還需要再把其它機器加進來k8s cluster中，才能正常運作。\n把其它臺機器加入這個k8s cluster 和controller prlane一樣，也要先設定好環境：linux環境設定和安裝k8s環境執行用的工具\n使用上面在建立cluster時，最後在畫面上顯示的join命令。\nkubeadm koin --token {cluster產生的token} 要注意的是，token只有24小時的有效期限。過期了需要回到controller plane產生新的token kubeadm token create --print-join-command ","date":"2023-06-29T09:34:49+08:00","permalink":"http://coding.fnsne.com/posts/install_k8s_environment/","title":"在乾淨環境建立k8s環境"},{"content":"Local Path Provisioner 是一個 Container Storage Interface (CSI)，也就是用來提供k8s環境下建立Persistent Volume (PV)的插件\n安裝 command\nkubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml 會建立local-path-storage這個namespace，要查看運行狀態，可以到裡面看log\nkubectl -n local-path-storage logs pods/local-path-provisioner-7f8667b75c-hjrrb 使用configmap來給予設定 kind: ConfigMap apiVersion: v1 metadata: name: local-path-config namespace: local-path-storage data: config.json: |- { \u0026#34;nodePathMap\u0026#34;:[ { \u0026#34;node\u0026#34;:\u0026#34;DEFAULT_PATH_FOR_NON_LISTED_NODES\u0026#34;, \u0026#34;paths\u0026#34;:[\u0026#34;/opt/local-path-provisioner\u0026#34;] }, { \u0026#34;node\u0026#34;:\u0026#34;yasker-lp-dev1\u0026#34;, \u0026#34;paths\u0026#34;:[\u0026#34;/opt/local-path-provisioner\u0026#34;, \u0026#34;/data1\u0026#34;] }, { \u0026#34;node\u0026#34;:\u0026#34;yasker-lp-dev3\u0026#34;, \u0026#34;paths\u0026#34;:[] } ] } setup: |- #!/bin/sh set -eu mkdir -m 0777 -p \u0026#34;$VOL_DIR\u0026#34; teardown: |- #!/bin/sh set -eu rm -rf \u0026#34;$VOL_DIR\u0026#34; helperPod.yaml: |- apiVersion: v1 kind: Pod metadata: name: helper-pod spec: containers: - name: helper-pod image: busybox config.json說明 nodePathMap 用來表示在各自的Node上，存資料的位置，規則如下\n沒有設定path的node會套用DEFAULT_PATH_FOR_NON_LISTED_NODES的設定 如果有列出來，但path是空的，代表這個Node不會允許用local-path-provisioner來建pv 每個node的path可以給好幾個位置，當裡面超過一個位置，每次建的時候會隨機選一個來用。 path一定要是絕對路徑 在同個node裡面，同一個path不能重複列。 同一個node不能重複列出來。 不允許使用/ 根目錄 sharedFileSystemPath 假如有一個file system有被mount在所有的Node上時，可以使用這個設定來指定，指定都用同一個位置。 和nodePathMap互斥，所以當有使用sharedFileSystemPath時，nodePathMap一定要是[] 只有使用了sharedFileSystemPath時，才會支援ReadOnlyMany、ReadWriteMany setup 每個volume在建立之前會先做的script，用來準備node上volume資料夾用。\nteardown 每個volume在被刪掉後會做的script，用來清掉node上volume資料夾用。\nhelperPod.yaml 用來執行setup和teardown的pod template\nsetup和teardown上面可以使用的環境變數 環境變數 說明 VOL_DIR 放置volume的路徑（nodePath寫的） VOL_MODE The PersistentVolume mode (Block or Filesystem). VOL_SIZE_BYTES Requested volume size in bytes. 設定storageClass來驅動local-path-provisioner provisioner欄位，官方Github寫的cluster.local/local-path-provisioner沒有用，反而要用rancher.io/local-path才有用。\napiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: incloud-lvm provisioner: rancher.io/local-path volumeBindingMode: WaitForFirstConsumer reclaimPolicy: Retain ","date":"2023-04-27T09:30:27+08:00","permalink":"http://coding.fnsne.com/posts/k8s_local_path_provisioner/","title":"Local Path Provisioner"},{"content":"關於鎖(lock) 畢業後，太久沒有用到相關的東西，概念開始和資料庫的transaction有點混淆了，所以拿出恐龍本讀回來。順便做一篇筆記\n一些專有名詞 名稱 說明 cooperation process （協作行程） 會操作到共同資源的不同process critical section 在各種cooperation process 裡面會操作到共同資源的code區塊 鎖想解決的問題 在多核心多執行序問世之前的單核心的時代，是一個核心切換來切換去的做不同事，在時間區間上每個時間點都只有一個process正在被cpu執行，如下圖。\n而在多核心問世以後開始會出現一些問題，如下圖。\n開始會發生圖上，兩個核心會同時執行不同的process ，這個時候可能會發生互相改到資料的問題。例如process B和D是要在印表機上面印出現在電腦的時間，就有可能會發生一下的輸出：\n假設兩個核心在執行processB和D的時間點是15:38和15:40\n15:153:840 這是因為兩個核心互相搶著輸出到印表機，但是順序亂掉的緣故。為了解決這個問題，鎖的概念被提了出來。\n鎖的用途 用來保護注critical section（以上面的例子來看，是Process B和Process D裡面，執行輸出資料到印表機的code block）。強制這兩個critical section，在同一個時間裡面，頂多只能有一個執行，另一個想要執行，得要等到另一個結束後，才能開始動作。\n鎖的種類 mutex lock（互斥鎖） 又稱自旋鎖，會讓這個process一直卡在loop裡面，直到能夠存取資料後，才跳出迴圈，開始執行這個critical section。\n因為實際上是一直在執行loop的狀態下做等待資源釋放的，所以它不需要使用到context switch，在獲得資源後的切換速度很快。所以常常被使用在共用資源都只會被佔用短短時間的情境下使用。\nmutex lock的概念是一個被相同mutex lock保護起來的多個critical section，一個時間裡只能有一個被執行，其他都得要等待它mutex lock釋放後，才能繼續搶，搶到的才能執行。\nsemaphore lock（號誌鎖） 和mutex lock不同，可以設定資源同一時間下，最多可以有S個process同時執行，當同時執行的critical section數目大於S時，會被停下來，等待到同時執行的critical section小於S時，才能繼續搶進去執行。\n如果要用mutex lock的方式執行，會讓很多process一直在執行loop，對於資源的浪費太大了，所以在semaphore lock的時候，會採用將process 暫停，將address存到lock S 的list裡面。等到有process把S給釋放，此時CPU會將S裡面的list，取出一個process出來執行。\n我混淆的概念釐清 鎖不是鎖住cpu，而是鎖住其他一樣需要這個鎖的process，讓同一個鎖保護的同一個（或者不同個）critical section ，一次最多只能有1（或者semaphore lock設定的數字）個process存取。\n被鎖保護住的critical section，只要裡面有存取某個共用資源的code，就能讓這項資源被鎖給保護，不被濫用。\n結論 鎖的概念就是為了要保護有限的資源，不要被無限的取用。例如可以利用鎖來保護對同一個檔案的更改，讓這個檔案一次只能被一個process更新，防止檔案內資料變得亂七八糟的。\n","date":"2022-09-20T16:35:44+08:00","permalink":"http://coding.fnsne.com/posts/operating_system_lock/","title":"關於鎖"},{"content":"網路上查到簡單說明transaction的例子，常常都是用轉賬來說明，但其實還有很多東西需要注意 帳戶轉賬，因為race condition的緣故，導致操作欄位的值被改錯。\nA有100，B有40。\nA轉100元給B，B轉20元給A，由兩個不同的client來處理操作。\n順序正確時：A會是減掉80\n但是當順序不正確，則數字會錯掉，例如A很早取得現在的餘額（100），但是更新數字0慢了，導致A最終變成0元，因為在B轉完帳後才更新值。\n以上的這個問題很明顯的是race condition。所謂的race condition是結果必須依賴與某種特定的順序，但是順序又並不是固定的，因此偶爾會出現錯誤。\n解決race condition的方法 為了要解決race condition，必須得要讓操作依照我們期望的順序才操作，才能預防不對的順序導致的錯誤。為了要達到這個目標，資料庫本身有提供兩種方法：\natomic update：資料庫提供的一個，對於單一欄位數值做相依於原本值的操作指令。這個操作過程會是atomic的，也就是不會操作到一半值被改掉而導致結果出錯。\nupdate products set quantity = quantity -1 where id = 1; 優點：因為只是對於欄位做簡單的數字運算並馬上更新上去，所以對於欄位的佔用時間相較下面的select for update較短，且資料庫會將這類atomic操作做優化，所以效能會比較好。\n缺點：只支援對於數值的簡單操作後更新，並不能做太複雜的運算。\nselect for update：這個操作被限制在transaction開起來的時候才能使用，使用時實際上就是將指定的欄位上一個更新的lock，此時直到commit之前，沒有其他client可以對這個欄位做任何更新。所以就能夠限制欄位更新的順序了。\nBegin; select quantity into $q from products where id = 1 for update; update products set quantity = $q-1; Commit; 優點：因為有上鎖了，所以幾乎可以用各種邏輯運算來更新欄位的值。\n缺點：因為會在欄位上面上鎖，並且持續到commit位置，所以對於效能會有很大的影響。\nversion scheme ：在table上面多新增一個欄位叫做version，來確定現在更新時的version，是否從拿值的時候到現在還沒有被更新過。程式可以藉由資料庫回傳的訊息，是否有更改到任何row來判斷是否更新成功。\nold_ver = `select money, version from bank where name = A` `update bank set money = 30, version = version + 1 where name = A and version = old_ver` 優點：能夠不使用任何鎖的時候實現。（或者還有其他我想不到的優點）\n缺點：可能會很浪費時間，尤其是當更新的頻率特別高的時候，可能很難可以得到把值更新下去的機會。並且失敗後得要重頭來過。可能會造成鎖的飢餓效應。\n一開始提到的例子裡面真正用到transaction功能的地方 利用transaction遇到錯誤時會rollback的特性，來在餘額小於0的時候，復原到還未轉賬之前的狀態。\n如何檢查餘額小於0，並在此時丟出錯誤呢？\n利用select for update鎖住欄位更新，在此時檢查，通過且做完操作後commit，釋放鎖。就可以避免此時有其他操作更動到這個帳戶的餘額。\n優點：可以實作各種複雜的檢查邏輯\n缺點：必須為這個帳戶的餘額上鎖，此時沒有其他人可以操作（也就是沒有其他人可以轉賬給他、領錢等操作），會導致效能低下。\n利用check constraint 來讓資料庫在欄位不符合規範的時候丟出錯誤。此時就可以配合transaction來rollback復原了。\n優點：因為check constraint是資料庫提供可以給欄位增加規範的設定，檢查會在更新的時候做，所以即使背後有使用鎖，所花費的時間會比用select for update還要少。\n缺點：只能依照資料庫提供的有限constraint來設定，並不一定能夠做到想要的規範。\n結論 遇到需要注意順序的操作，先試著能不能使用atomic update的方式來完成需求，沒有辦法的時候才會使用select for update的方式來限制進到這個transaction後，必須要操作完這邊的指令後，才能換別人改值。\n遇到需要檢查數值符不符合規範，先試著用check constraint來限制欄位，真的沒有辦法，才會採用select for update的方式來將欄位上鎖，來做檢查。\n參考資料 How to avoid the race condition and the negative value\ncheck constraint\nselect for update 詳解\ncheck constraint\n","date":"2022-09-14T16:22:17+08:00","permalink":"http://coding.fnsne.com/posts/how-database-sync/","title":"資料庫的同步"},{"content":"卡片盒筆記寫作有兩種方式 卡片盒筆記的做法，現在網路上很多影片、文章都有教了，所以我就不贅述了，這篇文章主要是記錄我如何在heptabase上面實作卡片盒筆記的方式。目前理解到的用法大致上有兩種方式。\n闡述延伸自己論點的做法 google搜尋卡片盒筆記最容易找到的是閱讀前哨戰站長瓦基的文章，張永錫老師有一次有和瓦基、朱騏有直播 ，我在這邊大概知道了瓦基使用heptabase的方式 ，大致上就是持續將相同大分類（同board）的卡片做多張卡片凝聚出共通點、複雜卡片切割成多張不需要上下文即可理解的論述、依照因果關係或層級架構為卡片作出連結。最後依照這個的架構輸出成文章。瓦基卡片盒筆記的文章\n不同卡片蹦發出新的東西 在張永錫老師在hahow的卡片盒筆記術 中，教導的寫文章方式，則是直接將所有搜尋到有所關聯的卡片複製到whimsical上面，再來整理排序，變成一張完整的文章。\n對我來說 我使用卡片盒筆記的目的是學習知識、整理思路，對於卡片盒筆記術課程中教導的用whimsical 配合notion放卡片，對於長期的專案來說，持續分裂、內聚的卡片很難同步。我的結論是，這套流程只比較適合一次結束的專案。\n所以在理清我需要讓專案持續成長，又要能夠視覺化看到因果和層級架構 這件事後，我馬上就花錢訂閱了heptabase。\n我實際的做法 整理卡片（收集、整理材料） white board為一項大項知識的庫，在裡面可以持續新增卡片，並且整理出順序。 持續做以下的流程\n為簡單的卡片查詢資料\n將資料整理成多項能夠獨立闡述內容的卡片（永久卡片）\n看看多張卡片可不可以凝聚出共同性，將其抽出來寫成卡片\n看看有沒有卡片寫了太多項內容，將內容封裝成多張卡片\n如果卡片之間有因果關係、架構層級，為其加上connection。\n在這邊要注意一點是，link和connection感覺很相似，我剛開始很混亂，不知道要怎麼使用。因為同時想要能闡述延伸自己論點的做法 、不同卡片蹦發出新的東西 ，所以會想要讓所有卡片之間的關聯都是用connection來連結。但是這個做法會讓畫面變得很混亂，反而會阻礙思考。後來在釐清了我使用卡片筆記的主要用法是闡述延伸自己論點的做法 後，就決定只讓有因係、層級架構關聯的卡片，使用connection，而其他的關聯則是在卡片內文使用link的方式來關聯。這個是在直播裡面學到的瓦基使用link和connect的時機\n寫成文章時 把所有想到和這篇文章相關的卡片用bullet list 來link到entry card\n這個方法是從瓦基學到的，文章/keyword card/entry卡片上面先用link把所有相關的卡片給連結進來。再來在這張卡片下面開始書寫文章。\n這個方法的完全是利用了heptabase的功能。\n首先heptabase的list可以隨意拖拉，來初步排列出書寫的順序。這個在各大筆記軟體（notion、evernote等）上的bullet list 其實都可以做得到。 Open in new tab → 再點選所有的link，heptabase會在右邊打開所有卡片，這樣可以快速的複製卡片內容過來變成初稿。 這篇文章大致上描述了我現在會在heptabase上面實作的卡片筆記流程，並且這篇文章也是我第一次在heptabase上面使用卡片筆記寫成的。總共花了一個下午和半個晚上研究、半個晚上整理成文章。\n","date":"2022-09-03T23:18:17+08:00","permalink":"http://coding.fnsne.com/posts/zetelkasten_in_heptabase_2022/","title":"我用heptabase來實作卡片盒筆記的方式"},{"content":"問題描述 明明有開啟toc功能，但是在旁邊的toc卻完全沒有顯示任何的標題鏈接。\n解法 這個問題的原因很簡單，是因為LoveIt預設會抓h2的標題，但我習慣從h1的標題開始寫，所以在toc上面沒有任何的標題存在。\n解決的方法很簡單，只要到設定（config.toml）裡面，加上\n[markup] [markup.tableOfContents] startLevel = 1 即可讓LoveIt從h1就開始抓到toc上面。\nreference LoveIt Github Issue 410 ","date":"2022-09-02T16:06:28+08:00","permalink":"http://coding.fnsne.com/posts/hugo_theme_loveit_toc_disappear/","title":"Hugo LoveIt 不會顯示toc"},{"content":"描述 原本在hugo上面放文章，是每篇文章一個資料夾，在其中放文章和會用到的圖片。每個文章資料夾都放在content/posts/。\ncontent/posts/ ├── post1 │ └── post1.md │ └── img1.jpg ├── post2 │ └── post2.md │ └── img2.jpg ├── post3 │ └── post3.md │ └── img3.jpg 因為覺得全部文章直接用資料夾名稱排序，覺得未來會變得很混亂，並且不好找尋文章位置，所以改成以下的結構：使用日期當主資料夾名稱。 雖然也是可以在文章資料夾名稱加上日期前綴來區分，但感覺還是會很亂。所以開始研究page bundle怎麼處理,試著將結構改成這樣。\nP.S. 在2024年8月的時候又改回hugo最原始的文章放置方式，發現全部文章放在一起，其實也不會太亂（是我寫太少文章了）。 並且使用日期當第一層資料夾名稱，我反而沒辦法一眼看出這裡面放的文章是什麼文章\ncontent/posts/ ├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── post2 │ └── post2.md │ └── img2.jpg ├── 2022-09-02 │ └── post3 │ └── post3.md │ └── img3.jpg 問題 看到跑出來的網頁上，載入圖片404的網址居然是還會增加一個文章名稱的資料夾，然後才存取圖片。以上面的例子來看， 打開網頁 post1頁面，網址會是domain/posts/2022-08-02/post1/post1/\n而圖片是呼叫domain/posts/2022-08-02/post1/post1/img1.jpg\n可是實際上到build出來的public裡面去看，這一個頁面的結構居然是長這樣\n├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── post1 │ └── index.html 解法 因為查到的所有資料，上面寫的md都命名為index，所以試著把post1.md改名為index.md，一切就正常了，而此時public裡面的資料結構變成長這樣。\n├── 2022-08-02 │ └── post1 │ └── post1.md │ └── img1.jpg │ └── index.html 看起來可能是因為bundle是抓index.md這個關鍵字的來製作頁面，如果沒有這個檔案，會用現有的*.md的檔案，各自建立一個它名稱的資料夾，然後在裡面建立index.html。所以原本的做法才會長成奇怪的結構。\nreference hugo github上面討論bundle的issue Markdown 技術文件寫作-處理圖檔\u0026mdash;黑暗執行續 hugo官網 Page Bundle ","date":"2022-09-02T14:36:26+08:00","permalink":"http://coding.fnsne.com/posts/hugo_bundle_organization/","title":"Hugo  Bundle問題"},{"content":"最近開始使用Goland來用hugo寫部落格文章，之前markdown的preview分頁都還很正常，但到了今天，突然之間只剩下一般的編輯界面，而且Goland好像還把它識別為html,旁邊會出現在各種瀏覽器上面的按鈕。\n而且使用hugo的shortcode還會出現網頁相關的錯誤訊息，在設定裡面查了一陣子才發現到。關於檔案的偵測少了.md的部分，只剩下markdown的部分\n將*.md加上去，一切的紅底線、還有markdown就都全部回來了。\n","date":"2022-09-01T20:21:30+08:00","permalink":"http://coding.fnsne.com/posts/jetbrains_goland_markdown_preview_disappear/","title":"Goland Markdown split editor消失的問題"},{"content":"內文 最近在godaddy上面購買網域，然後使用cloudflare來申請ssl並弄成https的連線。結果今天上來看blog卻發現進不去，錯誤訊息是太多的redirect了。 打開F12重整看看，還真的是持續進行著\n經過一段研究，發現只是這個問題很多人有遇到，只是因為CloudFlare的SSL設定設到了Flexible\n參考資料 Error 301 on DNS and HTTP Proxy ","date":"2022-09-01T17:01:39+08:00","permalink":"http://coding.fnsne.com/posts/cloudflare_ssl_redirect_loop/","title":"CloudFlare SSL in redirect loop"},{"content":"從物件導向的語言轉到Golang常常會遇到，不知道該怎麼在Golang實作類似多型和繼承的功能。這是因為Golang根本不是物件導向的語言。\n在網路上會看到一些文章，寫說可以使用可以embed來模擬繼承，但事實上embed的用途應該只是用來減少重複的程式碼，增加可讀性。像在io package裡面就很明顯，如interface ReadWriter就是用Reader和Writer 兩個interface組合起來的。\ntype ReadWriter interface { Reader Writer } 使用embed struct的方式來模擬繼承。為了要可以被抽換注入，還是得要同時implement一個interface。這樣還不如直接implement interface就好了。\n在Golang，唯一類似物件導向的東西只有 interface。只要有implement interface，就可以在宣告使用這個interface的地方使用。\n個人的理解，Golang把繼承的概念且分成兩個部分：embed和interface。embed struct (interface) 負責擴增fields (method); interface負責讓不同struct可以有相同的調用方式\nembed struct 的功能只是單純消除struct的field的重用而已。embed interface 也是如此，單純想要減少 method 裡面重複宣告 method 的程式碼。\n簡單來說，就是\n想要可以抽換，用interface; 想要減少重複可以用embed的方式包裝組合\n","date":"2022-08-02T20:01:59+08:00","permalink":"http://coding.fnsne.com/posts/golang_object_oriented/","title":"淺談在Golang上面的物件導向"}]